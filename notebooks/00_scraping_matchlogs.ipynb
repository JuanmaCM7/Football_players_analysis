{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421f9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Working directory set to: F:\\JCMDataCenter\\Proyectos\\Football_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to project root if running from 'notebooks/'\n",
    "notebook_dir = Path().resolve()\n",
    "project_root = notebook_dir.parent  # Assumes notebook is inside 'notebooks/'\n",
    "\n",
    "os.chdir(project_root)\n",
    "print(f\"‚úÖ Working directory set to: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1dbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9c22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Configuration\n",
    "CHROMEDRIVER_PATH = \"C:/Windows/System32/chromedriver.exe\"\n",
    "SLEEP_TIME = 8\n",
    "\n",
    "# List of players to scrape\n",
    "players = [\n",
    "    {\"name\": \"Viktor Gyokeres\", \"id\": \"4d5a9185\"}\n",
    "]\n",
    "\n",
    "# Output CSV file\n",
    "output_dir = Path(\"data/raw/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_csv = output_dir / \"matchlogs_fbref.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c34b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Scraping match logs for: Viktor Gyokeres\n",
      "   üìÖ Season: 2015 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2015/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2019-2020 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2019-2020/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2017-2018 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2017-2018/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2018-2019 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2018-2019/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2023-2024 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2023-2024/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2017 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2017/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2020-2021 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2020-2021/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2021-2022 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2021-2022/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2022-2023 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2022-2023/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: 2024-2025 ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/2024-2025/summary/Viktor-Gyokeres-Match-Logs\n",
      "   üìÖ Season: nat_tm ‚Äî https://fbref.com/en/players/4d5a9185/matchlogs/nat_tm/summary/Viktor-Gyokeres-Match-Logs\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# üöÄ Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(CHROMEDRIVER_PATH), options=options)\n",
    "\n",
    "# Initialize final storage\n",
    "all_matchlogs = []\n",
    "\n",
    "# üîÅ Helper: rename duplicated columns like 'Att', 'Cmp'\n",
    "def disambiguate_columns(columns):\n",
    "    counts = Counter()\n",
    "    new_columns = []\n",
    "    for col in columns:\n",
    "        counts[col] += 1\n",
    "        if counts[col] > 1:\n",
    "            new_columns.append(f\"{col}_{counts[col]}\")\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "    return new_columns\n",
    "\n",
    "# üîÑ Loop through each player\n",
    "for player in players:\n",
    "    player_name = player[\"name\"]\n",
    "    player_id = player[\"id\"]\n",
    "    profile_url = f\"https://fbref.com/en/players/{player_id}/{player_name.replace(' ', '-')}\"\n",
    "\n",
    "    print(f\"\\nüîé Scraping match logs for: {player_name}\")\n",
    "\n",
    "    try:\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # Extract season match log links\n",
    "        nav_section = soup.find(\"div\", id=\"inner_nav\")\n",
    "        matchlog_links = {\n",
    "            a[\"href\"] for a in nav_section.find_all(\"a\", href=True)\n",
    "            if \"/matchlogs/\" in a[\"href\"] and \"Match-Logs\" in a[\"href\"] and \"summary\" in a[\"href\"].lower()\n",
    "        } if nav_section else set()\n",
    "\n",
    "        if not matchlog_links:\n",
    "            print(\"‚ö†Ô∏è No match log links found.\")\n",
    "            continue\n",
    "\n",
    "        for relative_url in matchlog_links:\n",
    "            full_url = \"https://fbref.com\" + relative_url\n",
    "            season = relative_url.split(\"/matchlogs/\")[1].split(\"/\")[0]\n",
    "            print(f\"   üìÖ Season: {season} ‚Äî {full_url}\")\n",
    "\n",
    "            try:\n",
    "                driver.get(full_url)\n",
    "                time.sleep(SLEEP_TIME)\n",
    "                season_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                table = season_soup.find(\"table\", {\"id\": \"matchlogs_all\"})\n",
    "\n",
    "                if table:\n",
    "                    headers = table.find(\"thead\").find_all(\"tr\")[-1]\n",
    "                    raw_columns = [th.text.strip() for th in headers.find_all(\"th\")]\n",
    "                    columns = disambiguate_columns(raw_columns)  # ‚úÖ Rename duplicated columns\n",
    "\n",
    "                    for row in table.find(\"tbody\").find_all(\"tr\"):\n",
    "                        if \"class\" in row.attrs and \"thead\" in row[\"class\"]:\n",
    "                            continue\n",
    "                        cells = row.find_all([\"th\", \"td\"])\n",
    "                        values = [cell.text.strip() for cell in cells]\n",
    "                        row_data = dict(zip(columns, values))\n",
    "                        row_data[\"season\"] = season\n",
    "                        row_data[\"player_name\"] = player_name\n",
    "                        row_data[\"player_id\"] = player_id\n",
    "                        all_matchlogs.append(row_data)\n",
    "\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è No matchlogs_all table found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error scraping season {season}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping player {player_name}: {e}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46ea94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ New data appended to: F:\\JCMDataCenter\\Proyectos\\Football_analysis\\data\\raw\\matchlogs_fbref.csv | Total rows: 527\n"
     ]
    }
   ],
   "source": [
    "# üíæ Save all matchlogs to CSV\n",
    "if all_matchlogs:\n",
    "    df_matchlogs = pd.DataFrame(all_matchlogs)\n",
    "    output_csv = Path(\"data/raw/matchlogs_fbref.csv\")\n",
    "\n",
    "    if output_csv.exists():\n",
    "        # Load existing data\n",
    "        df_existing = pd.read_csv(output_csv, dtype=str)\n",
    "\n",
    "        # Append new rows\n",
    "        df_combined = pd.concat([df_existing, df_matchlogs], ignore_index=True)\n",
    "\n",
    "        # Remove duplicates (based on player_id + Date)\n",
    "        df_combined.drop_duplicates(subset=[\"player_id\", \"Date\"], inplace=True)\n",
    "\n",
    "        # Save combined data\n",
    "        df_combined.to_csv(output_csv, index=False)\n",
    "        print(f\"\\n‚úÖ New data appended to: {output_csv.resolve()} | Total rows: {len(df_combined)}\")\n",
    "    else:\n",
    "        # Save as new file\n",
    "        df_matchlogs.to_csv(output_csv, index=False)\n",
    "        print(f\"\\n‚úÖ Match logs saved to: {output_csv.resolve()}\")\n",
    "else:\n",
    "    print(\"\\nüö´ No data to save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
